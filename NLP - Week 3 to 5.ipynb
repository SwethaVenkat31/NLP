{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Similarity Using VSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Ex-3.1 Simple Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.3041257418754935\n"
     ]
    }
   ],
   "source": [
    "text1=\"Data Science is an interesting filed.\"\n",
    "text2=\"MAchine LEarning is a part of Data Science.\"\n",
    "vectorizer=TfidfVectorizer()\n",
    "X=vectorizer.fit_transform([text1,text2])\n",
    "similarity=cosine_similarity(X[0:1],X[1:2])\n",
    "print(\"Cosine Similarity:\",similarity[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex -  3.2 Advanced Similarity using Jaccard Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity: 0.07692307692307693\n"
     ]
    }
   ],
   "source": [
    "text1=\"Data Science involves statistics and programming.\"\n",
    "text2=\"Programming in Python is essential for Data Science.\"\n",
    "Set1=set(text1.lower().split())\n",
    "Set2=set(text2.lower().split())\n",
    "intersection=Set1.intersection(Set2)\n",
    "union=Set1.union(Set2)\n",
    "jaccard_similarity=len(intersection)/len(union)\n",
    "print(\"Jaccard Similarity:\",jaccard_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week - 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex - 4.1 Simple post tagging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: [('NLP', 'NNP'), ('is', 'VBZ'), ('fun', 'VBN'), ('to', 'TO'), ('learn', 'VB')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "text='NLP is fun to learn'\n",
    "tokens=nltk.word_tokenize(text)\n",
    "pos_tags=nltk.pos_tag(tokens)\n",
    "print(\"POS Tags:\",pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Ex - 4.2 Advacned POS Tagging with the frequency Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tag Frequency: Counter({'NNP': 1, 'VBZ': 1, 'VBN': 1, 'TO': 1, 'VB': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "text=\"NLP is a branch of Artificial Intelligence dealing with language.\"\n",
    "pos_tag=nltk.pos_tag(tokens)\n",
    "tokens=nltk.word_tokenize(text)\n",
    "tags=[tag for word, tag in pos_tags]\n",
    "frequency=Counter(tags)\n",
    "print(\"POS Tag Frequency:\",frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigrams and nGrams Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex - 5.1 Simple Bigram Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bigrams: [('NLP', 'is'), ('is', 'amazing'), ('amazing', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "from nltk import bigrams\n",
    "text='NLP is amazing.'\n",
    "tokens=nltk.word_tokenize(text)\n",
    "bigrams_list=list(bigrams(tokens))\n",
    "print(\"Bigrams:\",bigrams_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex - 5.2 Advanced ngram (Trigram) Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram: [('Nlp', 'makes', 'machines'), ('makes', 'machines', 'understand'), ('machines', 'understand', 'languages'), ('understand', 'languages', '.')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.util import ngrams\n",
    "text=\"Nlp makes machines understand languages.\"\n",
    "tokens=nltk.word_tokenize(text)\n",
    "trigram_list=list(ngrams(tokens,3))\n",
    "print(\"Trigram:\",trigram_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
